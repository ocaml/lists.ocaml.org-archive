<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [wg-parallel] About Lwt and Async
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:wg-parallel%40lists.ocaml.org?Subject=Re%3A%20%5Bwg-parallel%5D%20About%20Lwt%20and%20Async&In-Reply-To=%3CCANhEzE7Eb19vEhi9DKeLqCydZVr%3DkjVeWGDUHwHkT%2BCANn2cdA%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000006.html">
   <LINK REL="Next"  HREF="000008.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[wg-parallel] About Lwt and Async</H1>
    <B>Jeremie Dimino</B> 
    <A HREF="mailto:wg-parallel%40lists.ocaml.org?Subject=Re%3A%20%5Bwg-parallel%5D%20About%20Lwt%20and%20Async&In-Reply-To=%3CCANhEzE7Eb19vEhi9DKeLqCydZVr%3DkjVeWGDUHwHkT%2BCANn2cdA%40mail.gmail.com%3E"
       TITLE="[wg-parallel] About Lwt and Async">jdimino at janestreet.com
       </A><BR>
    <I>Mon Apr 29 16:12:25 BST 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="000006.html">[wg-parallel] About Lwt and Async
</A></li>
        <LI>Next message: <A HREF="000008.html">[wg-parallel] About Lwt and Async
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#7">[ date ]</a>
              <a href="thread.html#7">[ thread ]</a>
              <a href="subject.html#7">[ subject ]</a>
              <a href="author.html#7">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Mon, Apr 29, 2013 at 3:57 PM, Anil Madhavapeddy &lt;<A HREF="http://lists.ocaml.org/listinfo/wg-parallel">anil at recoil.org</A>&gt; wrote:
&gt;<i> Got it. I don't have a feel for the performance impact of such deferred
</I>&gt;<i> scheduling, except that the difference between busy-spinning if there are
</I>&gt;<i> outstanding requests, vs dropping into select/kqueue/epoll more frequently
</I>&gt;<i> is very significant.
</I>
As Stephen said there shouldn't be more select/kqueue/epoll calls.
The idea is to run all jobs until there is no one left (with a limit)
before doing the blocking select/kqueue/epoll call.

&gt;<i> For example, the Arakoon folks anecdotally reported a 20x performance loss
</I>&gt;<i> between a direct Unix implementation of their database layer vs an Lwt
</I>&gt;<i> one.  A loss that large can only be explained by context switching or
</I>&gt;<i> pathological scheduling somewhere (given we know that Lwt doesn't result
</I>&gt;<i> in a lot more allocation on the major heap).
</I>&gt;<i> <A HREF="http://www.slideshare.net/eikke/arakoon">http://www.slideshare.net/eikke/arakoon</A> (slide 14/15)
</I>&gt;<i> (I'm CCing Romain, who might have details).
</I>
I believe this was about the disk IO.  Disk IO are done using
preemptive threads since unix doesn't support asynchronous disk IO.
When data are cached it is indeed much slower.  You can get about the
same as direct IO after some tweaking: set the async_method to
'switch' and force the process to run only on one cpu. But the switch
method doesn't work with the threaded runtime.
</PRE>


<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000006.html">[wg-parallel] About Lwt and Async
</A></li>
	<LI>Next message: <A HREF="000008.html">[wg-parallel] About Lwt and Async
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#7">[ date ]</a>
              <a href="thread.html#7">[ thread ]</a>
              <a href="subject.html#7">[ subject ]</a>
              <a href="author.html#7">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.ocaml.org/listinfo/wg-parallel">More information about the wg-parallel
mailing list</a><br>
</body></html>
